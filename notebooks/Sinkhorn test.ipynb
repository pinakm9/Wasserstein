{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spiritual-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add modules to Python's search path\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import  torch\n",
    "#from geomloss import SamplesLoss\n",
    "import tensorflow as tf\n",
    "from modules import wasserstein as tfw\n",
    "import tensorflow_probability as tfp\n",
    "import scipy as sp\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "miniature-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nuse_cuda = torch.cuda.is_available()\\n# N.B.: We use float64 numbers to get nice limits when blur -> +infinity\\ndtype    = torch.cuda.DoubleTensor if use_cuda else torch.DoubleTensor\\n\\n# make a convenient wrapper for producing samples in form of a tensor\\ndef torch_sampler(mean, cov, size):\\n    samples = np.random.multivariate_normal(mean, cov, size)\\n    return torch.from_numpy(samples)\\n\\n# set up parameters for our two test distributions\\ndimension = 3\\nmean_1 = np.zeros(dimension)\\nmean_2 = mean_1 + 0.1 * np.ones(dimension)\\ncov_1 = np.identity(dimension)\\ncov_2 = cov_1\\n\\n# finally create the samplers our test distributions\\nsampler_1 = lambda size: torch_sampler(mean_1, cov_1, size)\\nsampler_2 = lambda size: torch_sampler(mean_2, cov_2, size)\\n\\n# test our samplers\\nprint(\"samples from distribution #1:\\n{}\".format(sampler_1(3)))\\nprint(\"samples from distribution #2:\\n{}\".format(sampler_2(3)))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# N.B.: We use float64 numbers to get nice limits when blur -> +infinity\n",
    "dtype    = torch.cuda.DoubleTensor if use_cuda else torch.DoubleTensor\n",
    "\n",
    "# make a convenient wrapper for producing samples in form of a tensor\n",
    "def torch_sampler(mean, cov, size):\n",
    "    samples = np.random.multivariate_normal(mean, cov, size)\n",
    "    return torch.from_numpy(samples)\n",
    "\n",
    "# set up parameters for our two test distributions\n",
    "dimension = 3\n",
    "mean_1 = np.zeros(dimension)\n",
    "mean_2 = mean_1 + 0.1 * np.ones(dimension)\n",
    "cov_1 = np.identity(dimension)\n",
    "cov_2 = cov_1\n",
    "\n",
    "# finally create the samplers our test distributions\n",
    "sampler_1 = lambda size: torch_sampler(mean_1, cov_1, size)\n",
    "sampler_2 = lambda size: torch_sampler(mean_2, cov_2, size)\n",
    "\n",
    "# test our samplers\n",
    "print(\"samples from distribution #1:\\n{}\".format(sampler_1(3)))\n",
    "print(\"samples from distribution #2:\\n{}\".format(sampler_2(3)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wrong-thermal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnum_samples_1 = 500\\nnum_samples_2 = 500\\nsamples_1 = sampler_1(num_samples_1)\\nsamples_2 = sampler_2(num_samples_2)\\nloss = SamplesLoss(\"sinkhorn\", p=2, blur=0.01, scaling=.99, backend=\"online\")\\nprint(np.sqrt(loss(samples_1, samples_2).item()))\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "num_samples_1 = 500\n",
    "num_samples_2 = 500\n",
    "samples_1 = sampler_1(num_samples_1)\n",
    "samples_2 = sampler_2(num_samples_2)\n",
    "loss = SamplesLoss(\"sinkhorn\", p=2, blur=0.01, scaling=.99, backend=\"online\")\n",
    "print(np.sqrt(loss(samples_1, samples_2).item()))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "square-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a convenient wrapper for producing samples in form of a tensor\n",
    "def tf_sampler(mean, cov, size):\n",
    "    samples = np.random.multivariate_normal(mean, cov, size)\n",
    "    return tf.convert_to_tensor(samples, dtype=tf.float32)\n",
    "\n",
    "# set up parameters for our two test distributions\n",
    "dimension = 5\n",
    "mean_1 = np.zeros(dimension)\n",
    "mean_2 = mean_1 + 0.0 \n",
    "cov_1 = 1.0 * np.identity(dimension)\n",
    "cov_2 = 1. * cov_1\n",
    "\n",
    "# finally create the samplers our test distributions\n",
    "sampler_1 = lambda size: tf_sampler(mean_1, cov_1, size)\n",
    "sampler_2 = lambda size: tf_sampler(mean_2, cov_2, size)\n",
    "\n",
    "# test our samplers\n",
    "#print(\"samples from distribution #1:\\n{}\".format(sampler_1(3)))\n",
    "#print(\"samples from distribution #2:\\n{}\".format(sampler_2(3)))\n",
    "\n",
    "# Wasserstein_2 formula\n",
    "def w2_formula(ensemble_1, ensemble_2, tf=True):\n",
    "    if tf:\n",
    "        ensemble_1 = ensemble_1.numpy()\n",
    "        ensemble_2 = ensemble_2.numpy()\n",
    "    m1 = np.mean(ensemble_1, axis=0)\n",
    "    m2 = np.mean(ensemble_2, axis=0)\n",
    "    C1 = np.cov(ensemble_1.T)\n",
    "    C2 = np.cov(ensemble_2.T)\n",
    "    r_C2 = sp.linalg.sqrtm(C2)\n",
    "    term_1 = np.linalg.norm(m1 - m2, ord=2)\n",
    "    term_2 = np.trace( C1 + C2 - 2.0 * sp.linalg.sqrtm(np.linalg.multi_dot([r_C2, C1, r_C2])) )\n",
    "    return np.sqrt(term_1**2 + term_2**2)\n",
    "\n",
    "def exact_w2(m1, m2, C1, C2):\n",
    "    term_1 = np.linalg.norm(m1 - m2, ord=2)\n",
    "    r_C2 = sp.linalg.sqrtm(C2)\n",
    "    term_2 = np.trace( C1 + C2 - 2.0 * sp.linalg.sqrtm(np.linalg.multi_dot([r_C2, C1, r_C2])) )\n",
    "    return np.sqrt(term_1**2 + term_2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "golden-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wasserstein_2, computed with Sinkhorn algorithm: 0.7612422704696655\n",
      "Wasserstein_2, computed with formula: 0.0\n",
      "Wasserstein_2, computed with Sinkhorn algorithm: 0.7869690656661987\n"
     ]
    }
   ],
   "source": [
    "num_samples_1 = 2000\n",
    "num_samples_2 = 2000\n",
    "samples_1 = sampler_1(num_samples_1)\n",
    "samples_2 = sampler_2(num_samples_2)\n",
    "#print(np.mean(samples_1, axis=0))\n",
    "#print(np.mean(samples_2, axis=0))\n",
    "loss = tfw.sinkhorn_loss(samples_1, samples_2, epsilon=0.01, num_iters=50, p=2)\n",
    "loss_S = tfw.sinkhorn_div(samples_2, samples_1, epsilon=0.1, num_iters=50, p=2)\n",
    "print(\"Wasserstein_2, computed with Sinkhorn algorithm: {}\".format(np.sqrt(loss)))\n",
    "print(\"Wasserstein_2, computed with formula: {}\".format(exact_w2(mean_1, mean_2, cov_1, cov_2)))\n",
    "print(\"Wasserstein_2, computed with Sinkhorn algorithm: {}\".format(np.sqrt(loss_S)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "running-rapid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.21308337771004ion #0\n",
      "63.65288704911929\n",
      "55.18977025188851ion #1\n",
      "60.97851891293679\n",
      "53.871060851606295on #2\n",
      "56.28064881218007\n",
      "62.91956113263058ion #3\n",
      "49.25666054874831\n",
      "58.01191433420417ion #4\n",
      "49.72419829436401\n",
      "56.63540741050371ion #5\n",
      "50.12857263794434\n",
      "65.45298595744013ion #6\n",
      "63.093220287005465\n",
      "55.56635887941306ion #7\n",
      "61.03778055202015\n",
      "56.82311714004696ion #8\n",
      "60.73557129684315\n",
      "52.09695787608822ion #9\n",
      "64.29578565722845\n",
      "60.24375783774974ion #10\n",
      "46.91571138785167\n",
      "59.94253926252081ion #11\n",
      "64.95313059143788\n",
      "55.01241919718278ion #12\n",
      "60.46799846056333\n",
      "65.28467734394468ion #13\n",
      "62.92972595770727\n",
      "56.906243037153274on #14\n",
      "63.70167461425046\n",
      "59.22558420955864ion #15\n",
      "49.219587079874614\n",
      "60.534732773705194on #16\n",
      "56.17959579452661\n",
      "54.77954655221756ion #17\n",
      "64.74856400029158\n",
      "57.39998251823479ion #18\n",
      "63.351051565978395\n",
      "56.22858609031845ion #19\n",
      "52.84711083322167\n",
      "59.644134698426505on #20\n",
      "59.5423329822403\n",
      "62.95824988256308ion #21\n",
      "62.30444863364514\n",
      "66.93097753246262ion #22\n",
      "46.29060934024443\n",
      "54.43491376625029ion #23\n",
      "52.811458612704364\n",
      "59.987850704814704on #24\n",
      "55.63301032463817\n",
      "59.71996144093801ion #25\n",
      "64.08632521819561\n",
      "71.54039466874373ion #26\n",
      "58.438773680295334\n",
      "53.886244483988ation #27\n",
      "61.642275898414916\n",
      "57.87066323098004ion #28\n",
      "58.390904063031705\n",
      "71.52162645844302ion #29\n",
      "60.75981176926593\n",
      "58.93689731641577ion #30\n",
      "62.71063539734107\n",
      "60.71055155980529ion #31\n",
      "56.61065731732847\n",
      "66.19241968327273ion #32\n",
      "60.68049691176101\n",
      "56.614031543898406on #33\n",
      "49.97010321984885\n",
      "58.69763016141221ion #34\n",
      "66.0362689660155\n",
      "53.80240277085404ion #35\n",
      "67.34012824746026\n",
      "59.22388932798063ion #36\n",
      "51.48540611795139\n",
      "59.25191695420898ion #37\n",
      "50.955464034014355\n",
      "63.79663249498088ion #38\n",
      "55.82393647992043\n",
      "65.38628625361599ion #39\n",
      "55.53807299131915\n",
      "59.32674916071618ion #40\n",
      "45.064719121266386\n",
      "62.64005879131643ion #41\n",
      "58.11225127985773\n",
      "52.60649908816949ion #42\n",
      "66.88040541141994\n",
      "69.78411537724124ion #43\n",
      "67.81589066553852\n",
      "58.93613312927958ion #44\n",
      "53.944953340224124\n",
      "69.4513087288994tion #45\n",
      "61.05852139974384\n",
      "55.847757863435675on #46\n",
      "59.4248670562694\n",
      "57.14269985700698ion #47\n",
      "64.30705062419506\n",
      "52.96350893953429ion #48\n",
      "55.56632103450192\n",
      "50.99676805815102ion #49\n",
      "58.39046210852475\n",
      "62.13028956827713ion #50\n",
      "68.43132168835534\n",
      "66.15160172279396ion #51\n",
      "61.76456976247214\n",
      "57.62635842391037ion #52\n",
      "58.27182625079385\n",
      "53.75132055695944ion #53\n",
      "63.683238049269015\n",
      "56.90431032512306ion #54\n",
      "59.6325030632486\n",
      "76.3695262006625tion #55\n",
      "65.20730457190083\n",
      "60.32856702763891ion #56\n",
      "49.05019874803231\n",
      "68.46731214928143ion #57\n",
      "72.48164256002262\n",
      "60.48668036804523ion #58\n",
      "54.09148785130346\n",
      "57.61420625008331ion #59\n",
      "60.76596735080332\n",
      "65.70099545515174ion #60\n",
      "64.43853915565205\n",
      "58.47744519133165ion #61\n",
      "57.27028240506993\n",
      "56.32241909352699ion #62\n",
      "63.19784699577343\n",
      "64.93579673013451ion #63\n",
      "63.00468547243645\n",
      "61.74680495212152ion #64\n",
      "61.038487583593444\n",
      "54.360049397067286on #65\n",
      "57.017864276294574\n",
      "61.272282708674716on #66\n",
      "67.38638957811482\n",
      "47.52809556641826ion #67\n",
      "50.728060827145235\n",
      "57.83284333078899ion #68\n",
      "58.3641450888147\n",
      "64.68672726188802ion #69\n",
      "64.08042475530664\n",
      "61.122614827672926on #70\n",
      "63.600877709656125\n",
      "57.85258961464581ion #71\n",
      "57.48014001643103\n",
      "65.44554501961262ion #72\n",
      "58.393882421642985\n",
      "52.86981678884467ion #73\n",
      "51.260016607924285\n",
      "56.96264981910744ion #74\n",
      "51.965527785934015\n",
      "68.12363377980897ion #75\n",
      "51.72943224798955\n",
      "62.4538705987101tion #76\n",
      "57.489378566127776\n",
      "61.996427299560594on #77\n",
      "53.67326002400018\n",
      "55.763612402458186on #78\n",
      "53.164824145140074\n",
      "53.42534567212186ion #79\n",
      "52.250834851232504\n",
      "68.4474318590797tion #80\n",
      "64.81685935343192\n",
      "53.58185637604611ion #81\n",
      "56.24710757497929\n",
      "58.64724591114922ion #82\n",
      "61.29044485024035\n",
      "60.504583450239096on #83\n",
      "61.90618685718366\n",
      "60.04360513555242ion #84\n",
      "59.30083582293815\n",
      "68.08965690059942ion #85\n",
      "64.98090737030057\n",
      "59.69233010075873ion #86\n",
      "66.80057321260624\n",
      "70.67307642416317ion #87\n",
      "56.10151310789048\n",
      "55.87281072266273ion #88\n",
      "61.84483975890398\n",
      "53.10942998859245ion #89\n",
      "53.98668308403358\n",
      "59.03448264038645ion #90\n",
      "58.48894656667023\n",
      "59.28755808442045ion #91\n",
      "55.68307670226104\n",
      "55.304676020883285on #92\n",
      "53.59440509520989\n",
      "65.10707903477332ion #93\n",
      "54.855581903347314\n",
      "54.09668437926362ion #94\n",
      "66.75103749158575\n",
      "53.245476605447976on #95\n",
      "57.796096926460066\n",
      "53.6122584801675tion #96\n",
      "54.784787253060784\n",
      "66.59571861264914ion #97\n",
      "62.93288010249249\n",
      "55.31207016108982ion #98\n",
      "52.107634443091456\n",
      "58.56185827793173ion #99\n",
      "63.58783290007252\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_sampler(dim=10, mean_a=-100., mean_b=100., cov_a=-1., cov_b=1.):\n",
    "    A = np.random.uniform(cov_a, cov_b, size=(dim, dim))\n",
    "    cov = np.dot(A.T, A)\n",
    "    print(np.linalg.norm(cov))\n",
    "    mean = np.random.uniform(mean_a, mean_b, size=dim)\n",
    "    return mean, cov, lambda size: tf_sampler(mean, cov, size)\n",
    "\n",
    "\n",
    "num_exps = 100\n",
    "dim = 10\n",
    "num_samples = 100\n",
    "cov_a = -2.\n",
    "cov_b = -cov_a\n",
    "w_s = np.zeros(num_exps)\n",
    "w_f = np.zeros(num_exps)\n",
    "for i in range(num_exps):\n",
    "    print('Working on iteration #{}'.format(i), end='\\r')\n",
    "    mean_1, cov_1, sampler_1 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    mean_2, cov_2, sampler_2 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    samples_1 = sampler_1(num_samples)\n",
    "    samples_2 = sampler_2(num_samples)\n",
    "    w_s[i] = np.sqrt(tfw.sinkhorn_loss(samples_1, samples_2, epsilon=0.01, num_iters=50, p=2))\n",
    "    w_f[i] = exact_w2(mean_1, mean_2, cov_1, cov_2) \n",
    "\n",
    "plt.scatter(w_s, w_f)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "psychological-banking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on iteration #99\n",
      "Number of failures = 0\n"
     ]
    }
   ],
   "source": [
    "# Triangle inequality\n",
    "\n",
    "num_exps = 100\n",
    "dim = 10\n",
    "num_samples = 200\n",
    "tri = np.zeros(num_exps)\n",
    "cov_a = -10.\n",
    "cov_b = -cov_a\n",
    "for i in range(num_exps):\n",
    "    print('Working on iteration #{}'.format(i), end='\\r')\n",
    "    mean_1, cov_1, sampler_1 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    mean_2, cov_2, sampler_2 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    mean_3, cov_3, sampler_3 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    samples_1 = sampler_1(num_samples)\n",
    "    samples_2 = sampler_2(num_samples)\n",
    "    samples_3 = sampler_3(num_samples)\n",
    "    w_12 = np.sqrt(tfw.sinkhorn_loss(samples_1, samples_2, epsilon=0.01, num_iters=50, p=2))\n",
    "    w_23 = np.sqrt(tfw.sinkhorn_loss(samples_2, samples_3, epsilon=0.01, num_iters=50, p=2))\n",
    "    w_13 = np.sqrt(tfw.sinkhorn_loss(samples_1, samples_3, epsilon=0.01, num_iters=50, p=2))\n",
    "    if w_12 + w_23 >= w_13:\n",
    "        tri[i] = 1.0\n",
    "print('\\nNumber of failures = {}'.format(num_exps - int(tri.sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "developmental-chocolate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.699871458401564on #0\n",
      "16.76883834455234\n",
      "14.293692413219672on #1\n",
      "13.407910249475403\n",
      "14.011974809950193on #2\n",
      "14.99734409766792\n",
      "14.406216159891267on #3\n",
      "13.159388423086902\n",
      "15.023351516041505on #4\n",
      "14.094890190470561\n",
      "13.080523961228907on #5\n",
      "14.420514811581596\n",
      "14.983384885574157on #6\n",
      "14.372005725122301\n",
      "13.936690898700546on #7\n",
      "15.178562934783299\n",
      "18.19225591480716ion #8\n",
      "12.550024926068081\n",
      "13.515316445506906on #9\n",
      "13.826960032823388\n",
      "14.635924528570827on #10\n",
      "13.884075918446788\n",
      "17.74089147720352ion #11\n",
      "14.8381644165007\n",
      "16.12390490178295ion #12\n",
      "14.146568199501809\n",
      "15.340511215477584on #13\n",
      "15.810464773326261\n",
      "14.07431832717446ion #14\n",
      "15.816751782541512\n",
      "14.820147713457466on #15\n",
      "14.850133701611066\n",
      "14.455503220124957on #16\n",
      "15.220832706465927\n",
      "15.713271435812011on #17\n",
      "15.056726621013256\n",
      "14.733170388259419on #18\n",
      "15.327659998394566\n",
      "13.52367813252385ion #19\n",
      "15.746484616339448\n",
      "18.917464590534994on #20\n",
      "14.322836887893967\n",
      "14.267999406714448on #21\n",
      "13.689673868239082\n",
      "12.756050802488392on #22\n",
      "13.11637162786462\n",
      "15.758479332243189on #23\n",
      "17.314944421942887\n",
      "14.80604776642804ion #24\n",
      "15.104667277353993\n",
      "16.263523324177434on #25\n",
      "12.72507363266779\n",
      "16.83342905263111ion #26\n",
      "13.259234398085814\n",
      "13.220290834130129on #27\n",
      "13.207484056364958\n",
      "16.566777646435792on #28\n",
      "16.380812822289446\n",
      "11.411944758354535on #29\n",
      "16.58990910549933\n",
      "13.387434998511129on #30\n",
      "13.178350133028959\n",
      "13.390048846712059on #31\n",
      "12.703720946382875\n",
      "14.936306921072063on #32\n",
      "14.96443932879444\n",
      "14.277662430135466on #33\n",
      "13.893159958261062\n",
      "15.870736935164855on #34\n",
      "14.751902405858726\n",
      "13.642207840617695on #35\n",
      "14.807368569758822\n",
      "14.407743053642383on #36\n",
      "15.044443695578583\n",
      "15.499139022461204on #37\n",
      "17.26178524963586\n",
      "12.88388961727198ion #38\n",
      "14.024045733567192\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-deb0180fcdfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0msamples_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampler_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0msamples_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampler_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mw_12\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msinkhorn_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mw_21\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msinkhorn_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#print(w_12, w_21)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\Wasserstein\\modules\\wasserstein.py\u001b[0m in \u001b[0;36msinkhorn_loss\u001b[1;34m(x, y, x_weights, y_weights, epsilon, num_iters, p)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_weights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m  \u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_weights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mlse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\Wasserstein\\modules\\wasserstein.py\u001b[0m in \u001b[0;36mM\u001b[1;34m(u, v)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;34m\"Modified cost for logarithmic updates\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;34m\"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_logsumexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mneg\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m   6233\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6234\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6235\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   6236\u001b[0m         _ctx, \"Neg\", name, x)\n\u001b[0;32m   6237\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Symmetry\n",
    "\n",
    "num_exps = 100\n",
    "dim = 10\n",
    "num_samples = 200\n",
    "sym = np.zeros(num_exps)\n",
    "cov_a = -1.\n",
    "cov_b = -cov_a\n",
    "for i in range(num_exps):\n",
    "    print('Working on iteration #{}'.format(i), end='\\r')\n",
    "    mean_1, cov_1, sampler_1 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    mean_2, cov_2, sampler_2 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    samples_1 = sampler_1(num_samples)\n",
    "    samples_2 = sampler_2(num_samples)\n",
    "    w_12 = np.sqrt(tfw.sinkhorn_loss(samples_1, samples_2, epsilon=0.01, num_iters=500, p=2))\n",
    "    w_21 = np.sqrt(tfw.sinkhorn_loss(samples_2, samples_1, epsilon=0.01, num_iters=500, p=2))\n",
    "    #print(w_12, w_21)\n",
    "    if abs(w_12 - w_21)/w_12 < 1e-2:\n",
    "        sym[i] = 1.0\n",
    "print('\\nNumber of failures = {}'.format(num_exps - int(sym.sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "latter-vacation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on iteration #99\n",
      "Number of failures = 0\n"
     ]
    }
   ],
   "source": [
    "# Identity\n",
    "\n",
    "num_exps = 100\n",
    "dim = 10\n",
    "num_samples = 200\n",
    "id_ = np.zeros(num_exps)\n",
    "cov_a = -10.\n",
    "cov_b = -cov_a\n",
    "for i in range(num_exps):\n",
    "    print('Working on iteration #{}'.format(i), end='\\r')\n",
    "    mean_1, cov_1, sampler_1 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    samples_1 = sampler_1(num_samples)\n",
    "    w = np.sqrt(tfw.sinkhorn_loss(samples_1, samples_1, epsilon=0.01, num_iters=50, p=2))\n",
    "    if w == 0.:\n",
    "        id_[i] = 1.0\n",
    "print('\\nNumber of failures = {}'.format(num_exps - int(id_.sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-faculty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
