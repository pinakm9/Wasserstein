{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spiritual-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add modules to Python's search path\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import  torch\n",
    "#from geomloss import SamplesLoss\n",
    "import tensorflow as tf\n",
    "from modules import wasserstein as tfw\n",
    "import tensorflow_probability as tfp\n",
    "import scipy as sp\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "miniature-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nuse_cuda = torch.cuda.is_available()\\n# N.B.: We use float64 numbers to get nice limits when blur -> +infinity\\ndtype    = torch.cuda.DoubleTensor if use_cuda else torch.DoubleTensor\\n\\n# make a convenient wrapper for producing samples in form of a tensor\\ndef torch_sampler(mean, cov, size):\\n    samples = np.random.multivariate_normal(mean, cov, size)\\n    return torch.from_numpy(samples)\\n\\n# set up parameters for our two test distributions\\ndimension = 3\\nmean_1 = np.zeros(dimension)\\nmean_2 = mean_1 + 0.1 * np.ones(dimension)\\ncov_1 = np.identity(dimension)\\ncov_2 = cov_1\\n\\n# finally create the samplers our test distributions\\nsampler_1 = lambda size: torch_sampler(mean_1, cov_1, size)\\nsampler_2 = lambda size: torch_sampler(mean_2, cov_2, size)\\n\\n# test our samplers\\nprint(\"samples from distribution #1:\\n{}\".format(sampler_1(3)))\\nprint(\"samples from distribution #2:\\n{}\".format(sampler_2(3)))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# N.B.: We use float64 numbers to get nice limits when blur -> +infinity\n",
    "dtype    = torch.cuda.DoubleTensor if use_cuda else torch.DoubleTensor\n",
    "\n",
    "# make a convenient wrapper for producing samples in form of a tensor\n",
    "def torch_sampler(mean, cov, size):\n",
    "    samples = np.random.multivariate_normal(mean, cov, size)\n",
    "    return torch.from_numpy(samples)\n",
    "\n",
    "# set up parameters for our two test distributions\n",
    "dimension = 3\n",
    "mean_1 = np.zeros(dimension)\n",
    "mean_2 = mean_1 + 0.1 * np.ones(dimension)\n",
    "cov_1 = np.identity(dimension)\n",
    "cov_2 = cov_1\n",
    "\n",
    "# finally create the samplers our test distributions\n",
    "sampler_1 = lambda size: torch_sampler(mean_1, cov_1, size)\n",
    "sampler_2 = lambda size: torch_sampler(mean_2, cov_2, size)\n",
    "\n",
    "# test our samplers\n",
    "print(\"samples from distribution #1:\\n{}\".format(sampler_1(3)))\n",
    "print(\"samples from distribution #2:\\n{}\".format(sampler_2(3)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wrong-thermal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnum_samples_1 = 500\\nnum_samples_2 = 500\\nsamples_1 = sampler_1(num_samples_1)\\nsamples_2 = sampler_2(num_samples_2)\\nloss = SamplesLoss(\"sinkhorn\", p=2, blur=0.01, scaling=.99, backend=\"online\")\\nprint(np.sqrt(loss(samples_1, samples_2).item()))\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "num_samples_1 = 500\n",
    "num_samples_2 = 500\n",
    "samples_1 = sampler_1(num_samples_1)\n",
    "samples_2 = sampler_2(num_samples_2)\n",
    "loss = SamplesLoss(\"sinkhorn\", p=2, blur=0.01, scaling=.99, backend=\"online\")\n",
    "print(np.sqrt(loss(samples_1, samples_2).item()))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "square-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a convenient wrapper for producing samples in form of a tensor\n",
    "def tf_sampler(mean, cov, size):\n",
    "    samples = np.random.multivariate_normal(mean, cov, size)\n",
    "    return tf.convert_to_tensor(samples, dtype=tf.float32)\n",
    "\n",
    "# set up parameters for our two test distributions\n",
    "dimension = 5\n",
    "mean_1 = np.zeros(dimension)\n",
    "mean_2 = mean_1 + 0.0 \n",
    "cov_1 = 1.0 * np.identity(dimension)\n",
    "cov_2 = 1.0 * cov_1\n",
    "\n",
    "# finally create the samplers our test distributions\n",
    "sampler_1 = lambda size: tf_sampler(mean_1, cov_1, size)\n",
    "sampler_2 = lambda size: tf_sampler(mean_2, cov_2, size)\n",
    "\n",
    "# test our samplers\n",
    "#print(\"samples from distribution #1:\\n{}\".format(sampler_1(3)))\n",
    "#print(\"samples from distribution #2:\\n{}\".format(sampler_2(3)))\n",
    "\n",
    "# Wasserstein_2 formula\n",
    "def w2_formula(ensemble_1, ensemble_2, tf=True):\n",
    "    if tf:\n",
    "        ensemble_1 = ensemble_1.numpy()\n",
    "        ensemble_2 = ensemble_2.numpy()\n",
    "    m1 = np.mean(ensemble_1, axis=0)\n",
    "    m2 = np.mean(ensemble_2, axis=0)\n",
    "    C1 = np.cov(ensemble_1.T)\n",
    "    C2 = np.cov(ensemble_2.T)\n",
    "    r_C2 = sp.linalg.sqrtm(C2)\n",
    "    term_1 = np.linalg.norm(m1 - m2, ord=2)\n",
    "    term_2 = np.trace( C1 + C2 - 2.0 * sp.linalg.sqrtm(np.linalg.multi_dot([r_C2, C1, r_C2])) )\n",
    "    return np.sqrt(term_1**2 + term_2**2)\n",
    "\n",
    "def exact_w2(m1, m2, C1, C2):\n",
    "    term_1 = np.linalg.norm(m1 - m2, ord=2)\n",
    "    r_C2 = sp.linalg.sqrtm(C2)\n",
    "    term_2 = np.trace( C1 + C2 - 2.0 * sp.linalg.sqrtm(np.linalg.multi_dot([r_C2, C1, r_C2])) )\n",
    "    return np.sqrt(term_1**2 + term_2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "golden-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wasserstein_2, computed with formula: 0.0\n",
      "Wasserstein_2, computed with Sinkhorn algorithm: 0.9900411367416382\n"
     ]
    }
   ],
   "source": [
    "num_samples_1 = 500\n",
    "num_samples_2 = 500\n",
    "samples_1 = sampler_1(num_samples_1)\n",
    "samples_2 = sampler_2(num_samples_2)\n",
    "#print(np.mean(samples_1, axis=0))\n",
    "#print(np.mean(samples_2, axis=0))\n",
    "#loss = tfw.sinkhorn_loss(samples_1, samples_1, epsilon=0.01, num_iters=50, p=2)\n",
    "loss_S = tfw.sinkhorn_loss(samples_1, samples_2, epsilon=0.01, num_iters=50, p=2)\n",
    "#print(\"Wasserstein_2, computed with Sinkhorn algorithm: {}\".format(np.sqrt(loss)))\n",
    "print(\"Wasserstein_2, computed with formula: {}\".format(exact_w2(mean_1, mean_2, cov_1, cov_2)))\n",
    "print(\"Wasserstein_2, computed with Sinkhorn algorithm: {}\".format(np.sqrt(loss_S)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "running-rapid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on iteration #99\r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_sampler(dim=10, mean_a=-100., mean_b=100., cov_a=-1., cov_b=1.):\n",
    "    A = np.random.uniform(cov_a, cov_b, size=(dim, dim))\n",
    "    cov = np.dot(A.T, A)\n",
    "    #print(np.linalg.norm(cov))\n",
    "    mean = np.random.uniform(mean_a, mean_b, size=dim)\n",
    "    return mean, cov, lambda size: tf_sampler(mean, cov, size)\n",
    "\n",
    "\n",
    "num_exps = 100\n",
    "dim = 10\n",
    "num_samples = 100\n",
    "cov_a = -2.\n",
    "cov_b = -cov_a\n",
    "w_s = np.zeros(num_exps)\n",
    "w_f = np.zeros(num_exps)\n",
    "for i in range(num_exps):\n",
    "    print('Working on iteration #{}'.format(i), end='\\r')\n",
    "    mean_1, cov_1, sampler_1 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    mean_2, cov_2, sampler_2 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    samples_1 = sampler_1(num_samples)\n",
    "    samples_2 = sampler_2(num_samples)\n",
    "    w_s[i] = np.sqrt(tfw.sinkhorn_div_tf(samples_1, samples_2, epsilon=0.01, num_iters=50, p=2))\n",
    "    w_f[i] = exact_w2(mean_1, mean_2, cov_1, cov_2) \n",
    "\n",
    "plt.scatter(w_s, w_f)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "psychological-banking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on iteration #99\n",
      "Number of failures = 0\n"
     ]
    }
   ],
   "source": [
    "# Triangle inequality\n",
    "\n",
    "num_exps = 100\n",
    "dim = 10\n",
    "num_samples = 200\n",
    "tri = np.zeros(num_exps)\n",
    "cov_a = -10.\n",
    "cov_b = -cov_a\n",
    "for i in range(num_exps):\n",
    "    print('Working on iteration #{}'.format(i), end='\\r')\n",
    "    mean_1, cov_1, sampler_1 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    mean_2, cov_2, sampler_2 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    mean_3, cov_3, sampler_3 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    samples_1 = sampler_1(num_samples)\n",
    "    samples_2 = sampler_2(num_samples)\n",
    "    samples_3 = sampler_3(num_samples)\n",
    "    w_12 = np.sqrt(tfw.sinkhorn_loss(samples_1, samples_2, epsilon=0.01, num_iters=50, p=2))\n",
    "    w_23 = np.sqrt(tfw.sinkhorn_loss(samples_2, samples_3, epsilon=0.01, num_iters=50, p=2))\n",
    "    w_13 = np.sqrt(tfw.sinkhorn_loss(samples_1, samples_3, epsilon=0.01, num_iters=50, p=2))\n",
    "    if w_12 + w_23 >= w_13:\n",
    "        tri[i] = 1.0\n",
    "print('\\nNumber of failures = {}'.format(num_exps - int(tri.sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "developmental-chocolate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on iteration #0\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5c2d718c567f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0msamples_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampler_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mw_12\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msinkhorn_div\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mw_21\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msinkhorn_div\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;31m#print(w_12, w_21)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mw12\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mw_21\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#abs(w_12 - w_21)/w_12 < 1e-2:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Wasserstein\\modules\\wasserstein.py\u001b[0m in \u001b[0;36msinkhorn_div\u001b[1;34m(x, y, alpha, beta, epsilon, num_iters, p)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[0mOT_alpha_beta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_cost_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Wasserstein\\modules\\wasserstein.py\u001b[0m in \u001b[0;36mcompute_cost_matrix\u001b[1;34m(x, y, p)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m   1034\u001b[0m       \u001b[0mvar_empty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m       \u001b[0mpacked_begin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpacked_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpacked_strides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar_empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m     return strided_slice(\n\u001b[0m\u001b[0;32m   1037\u001b[0m         \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[0mpacked_begin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[0;32m   1207\u001b[0m     \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1209\u001b[1;33m   op = gen_array_ops.strided_slice(\n\u001b[0m\u001b[0;32m   1210\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  10438\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10439\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10440\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m  10441\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"StridedSlice\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"begin_mask\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10442\u001b[0m         \u001b[0mbegin_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ellipsis_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Symmetry\n",
    "\n",
    "num_exps = 100\n",
    "dim = 10\n",
    "num_samples = 200\n",
    "sym = np.zeros(num_exps)\n",
    "cov_a = -1.\n",
    "cov_b = -cov_a\n",
    "for i in range(num_exps):\n",
    "    print('Working on iteration #{}'.format(i), end='\\r')\n",
    "    mean_1, cov_1, sampler_1 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    mean_2, cov_2, sampler_2 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    samples_1 = sampler_1(num_samples)\n",
    "    samples_2 = sampler_2(num_samples)\n",
    "    w_12 = np.sqrt(tfw.sinkhorn_div_tf(samples_1, samples_2, epsilon=0.01, num_iters=50, p=2))\n",
    "    w_21 = np.sqrt(tfw.sinkhorn_div_tf(samples_2, samples_1, epsilon=0.01, num_iters=50, p=2))\n",
    "    #print(w_12, w_21)\n",
    "    if w12 == w_21:#abs(w_12 - w_21)/w_12 < 1e-2:\n",
    "        sym[i] = 1.0\n",
    "print('\\nNumber of failures = {}'.format(num_exps - int(sym.sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "latter-vacation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on iteration #99\n",
      "Number of failures = 0\n"
     ]
    }
   ],
   "source": [
    "# Identity\n",
    "\n",
    "num_exps = 100\n",
    "dim = 10\n",
    "num_samples = 200\n",
    "id_ = np.zeros(num_exps)\n",
    "cov_a = -10.\n",
    "cov_b = -cov_a\n",
    "for i in range(num_exps):\n",
    "    print('Working on iteration #{}'.format(i), end='\\r')\n",
    "    mean_1, cov_1, sampler_1 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    samples_1 = sampler_1(num_samples)\n",
    "    w = np.sqrt(tfw.sinkhorn_loss(samples_1, samples_1, epsilon=0.01, num_iters=50, p=2))\n",
    "    if w == 0.:\n",
    "        id_[i] = 1.0\n",
    "print('\\nNumber of failures = {}'.format(num_exps - int(id_.sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-faculty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
