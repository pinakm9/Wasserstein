{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spiritual-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add modules to Python's search path\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import  torch\n",
    "#from geomloss import SamplesLoss\n",
    "import tensorflow as tf\n",
    "from modules import wasserstein as tfw\n",
    "import tensorflow_probability as tfp\n",
    "import scipy as sp\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "miniature-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nuse_cuda = torch.cuda.is_available()\\n# N.B.: We use float64 numbers to get nice limits when blur -> +infinity\\ndtype    = torch.cuda.DoubleTensor if use_cuda else torch.DoubleTensor\\n\\n# make a convenient wrapper for producing samples in form of a tensor\\ndef torch_sampler(mean, cov, size):\\n    samples = np.random.multivariate_normal(mean, cov, size)\\n    return torch.from_numpy(samples)\\n\\n# set up parameters for our two test distributions\\ndimension = 3\\nmean_1 = np.zeros(dimension)\\nmean_2 = mean_1 + 0.1 * np.ones(dimension)\\ncov_1 = np.identity(dimension)\\ncov_2 = cov_1\\n\\n# finally create the samplers our test distributions\\nsampler_1 = lambda size: torch_sampler(mean_1, cov_1, size)\\nsampler_2 = lambda size: torch_sampler(mean_2, cov_2, size)\\n\\n# test our samplers\\nprint(\"samples from distribution #1:\\n{}\".format(sampler_1(3)))\\nprint(\"samples from distribution #2:\\n{}\".format(sampler_2(3)))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# N.B.: We use float64 numbers to get nice limits when blur -> +infinity\n",
    "dtype    = torch.cuda.DoubleTensor if use_cuda else torch.DoubleTensor\n",
    "\n",
    "# make a convenient wrapper for producing samples in form of a tensor\n",
    "def torch_sampler(mean, cov, size):\n",
    "    samples = np.random.multivariate_normal(mean, cov, size)\n",
    "    return torch.from_numpy(samples)\n",
    "\n",
    "# set up parameters for our two test distributions\n",
    "dimension = 3\n",
    "mean_1 = np.zeros(dimension)\n",
    "mean_2 = mean_1 + 0.1 * np.ones(dimension)\n",
    "cov_1 = np.identity(dimension)\n",
    "cov_2 = cov_1\n",
    "\n",
    "# finally create the samplers our test distributions\n",
    "sampler_1 = lambda size: torch_sampler(mean_1, cov_1, size)\n",
    "sampler_2 = lambda size: torch_sampler(mean_2, cov_2, size)\n",
    "\n",
    "# test our samplers\n",
    "print(\"samples from distribution #1:\\n{}\".format(sampler_1(3)))\n",
    "print(\"samples from distribution #2:\\n{}\".format(sampler_2(3)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wrong-thermal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnum_samples_1 = 500\\nnum_samples_2 = 500\\nsamples_1 = sampler_1(num_samples_1)\\nsamples_2 = sampler_2(num_samples_2)\\nloss = SamplesLoss(\"sinkhorn\", p=2, blur=0.01, scaling=.99, backend=\"online\")\\nprint(np.sqrt(loss(samples_1, samples_2).item()))\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "num_samples_1 = 500\n",
    "num_samples_2 = 500\n",
    "samples_1 = sampler_1(num_samples_1)\n",
    "samples_2 = sampler_2(num_samples_2)\n",
    "loss = SamplesLoss(\"sinkhorn\", p=2, blur=0.01, scaling=.99, backend=\"online\")\n",
    "print(np.sqrt(loss(samples_1, samples_2).item()))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "square-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a convenient wrapper for producing samples in form of a tensor\n",
    "def tf_sampler(mean, cov, size):\n",
    "    samples = np.random.multivariate_normal(mean, cov, size)\n",
    "    return tf.convert_to_tensor(samples, dtype=tf.float32)\n",
    "\n",
    "# set up parameters for our two test distributions\n",
    "dimension = 10\n",
    "mean_1 = np.zeros(dimension)\n",
    "mean_2 = mean_1 + 10.0 \n",
    "cov_1 = 0.1 * np.identity(dimension)\n",
    "cov_2 = 100. * cov_1\n",
    "\n",
    "# finally create the samplers our test distributions\n",
    "sampler_1 = lambda size: tf_sampler(mean_1, cov_1, size)\n",
    "sampler_2 = lambda size: tf_sampler(mean_2, cov_2, size)\n",
    "\n",
    "# test our samplers\n",
    "#print(\"samples from distribution #1:\\n{}\".format(sampler_1(3)))\n",
    "#print(\"samples from distribution #2:\\n{}\".format(sampler_2(3)))\n",
    "\n",
    "# Wasserstein_2 formula\n",
    "def w2_formula(ensemble_1, ensemble_2, tf=True):\n",
    "    if tf:\n",
    "        ensemble_1 = ensemble_1.numpy()\n",
    "        ensemble_2 = ensemble_2.numpy()\n",
    "    m1 = np.mean(ensemble_1, axis=0)\n",
    "    m2 = np.mean(ensemble_2, axis=0)\n",
    "    C1 = np.cov(ensemble_1.T)\n",
    "    C2 = np.cov(ensemble_2.T)\n",
    "    r_C2 = sp.linalg.sqrtm(C2)\n",
    "    term_1 = np.linalg.norm(m1 - m2, ord=2)\n",
    "    term_2 = np.trace( C1 + C2 - 2.0 * sp.linalg.sqrtm(np.linalg.multi_dot([r_C2, C1, r_C2])) )\n",
    "    return np.sqrt(term_1**2 + term_2**2)\n",
    "\n",
    "def exact_w2(m1, m2, C1, C2):\n",
    "    term_1 = np.linalg.norm(m1 - m2, ord=2)\n",
    "    r_C2 = sp.linalg.sqrtm(C2)\n",
    "    term_2 = np.trace( C1 + C2 - 2.0 * sp.linalg.sqrtm(np.linalg.multi_dot([r_C2, C1, r_C2])) )\n",
    "    return np.sqrt(term_1**2 + term_2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_1 = 200\n",
    "num_samples_2 = 200\n",
    "samples_1 = sampler_1(num_samples_1)\n",
    "samples_2 = sampler_2(num_samples_2)\n",
    "#print(np.mean(samples_1, axis=0))\n",
    "#print(np.mean(samples_2, axis=0))\n",
    "loss = tfw.sinkhorn_loss(samples_1, samples_2, epsilon=0.01, num_iters=50, p=2)\n",
    "loss_S = tfw.sinkhorn_div(samples_2, samples_1, epsilon=0.1, num_iters=50, p=2)\n",
    "print(\"Wasserstein_2, computed with Sinkhorn algorithm: {}\".format(np.sqrt(loss)))\n",
    "print(\"Wasserstein_2, computed with formula: {}\".format(exact_w2(mean_1, mean_2, cov_1, cov_2)))\n",
    "print(\"Wasserstein_2, computed with Sinkhorn algorithm: {}\".format(np.sqrt(loss_S)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "running-rapid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.66184171245476ion #0\n",
      "55.95652508007022\n",
      "68.36225233885033ion #1\n",
      "54.711413144219826\n",
      "55.428602842286836on #2\n",
      "57.62488814215459\n",
      "66.91436072068487ion #3\n",
      "66.01473948318898\n",
      "54.82623971911553ion #4\n",
      "55.825528529671466\n",
      "66.36886776952116ion #5\n",
      "62.11423424390933\n",
      "61.63241803467923ion #6\n",
      "57.892616101347606\n",
      "54.66126337439349ion #7\n",
      "85.44813340519762\n",
      "66.40294143690211ion #8\n",
      "62.426053403828945\n",
      "58.8623454132823tion #9\n",
      "61.51909276629149\n",
      "58.71900540490499ion #10\n",
      "60.678930358293805\n",
      "58.98517827771012ion #11\n",
      "68.35182105994686\n",
      "63.560085764683215on #12\n",
      "50.44431180227022\n",
      "49.19079617943104ion #13\n",
      "60.9410572291694\n",
      "50.05638235313201ion #14\n",
      "42.23305439541086\n",
      "52.72003471074757ion #15\n",
      "48.834147041703865\n",
      "50.173726504440396on #16\n",
      "58.814962897310714\n",
      "47.56595935999352ion #17\n",
      "58.97253879397782\n",
      "67.51813801298921ion #18\n",
      "66.9596844991082\n",
      "59.63364066854978ion #19\n",
      "54.07109034112482\n",
      "67.1730149672447tion #20\n",
      "60.805748396367136\n",
      "62.12470832285866ion #21\n",
      "61.62764964707927\n",
      "64.57760004245567ion #22\n",
      "64.62733431316725\n",
      "50.299425529537196on #23\n",
      "58.730480288726575\n",
      "54.54899256145611ion #24\n",
      "55.22530848259466\n",
      "67.51725141382089ion #25\n",
      "61.812725397904714\n",
      "48.589390688240414on #26\n",
      "50.45511738436746\n",
      "59.64889687068412ion #27\n",
      "49.37152292540365\n",
      "58.33062458176409ion #28\n",
      "49.78120473199771\n",
      "56.83226628722864ion #29\n",
      "50.503600504476964\n",
      "65.55349527606413ion #30\n",
      "51.428021360776015\n",
      "62.400381983325154on #31\n",
      "56.554390038200154\n",
      "52.796503655083214on #32\n",
      "51.54196141760569\n",
      "50.3338657432079tion #33\n",
      "59.43712831813614\n",
      "64.19957793910294ion #34\n",
      "55.33577171235225\n",
      "64.36290825618616ion #35\n",
      "58.70702876044291\n",
      "57.21034413341864ion #36\n",
      "69.42505748077346\n",
      "56.423313715481854on #37\n",
      "64.03940434555051\n",
      "64.15588030895582ion #38\n",
      "57.62022905623258\n",
      "59.65207644774722ion #39\n",
      "56.67552212709062\n",
      "62.497819545130675on #40\n",
      "48.904546777014495\n",
      "64.92252258758468ion #41\n",
      "67.1693177535333\n",
      "62.38953699781299ion #42\n",
      "69.0263773777774\n",
      "42.8317582260492tion #43\n",
      "62.7099838306234\n",
      "59.416413363259565on #44\n",
      "61.87079509142861\n",
      "51.720885654061604on #45\n",
      "53.80743806780358\n",
      "56.17117871079828ion #46\n",
      "69.84165428469097\n",
      "55.28314918915791ion #47\n",
      "56.250441738991846\n",
      "55.65038719592404ion #48\n",
      "72.38800515131754\n",
      "58.7146110825853tion #49\n",
      "62.90413645707137\n",
      "68.95145099820826ion #50\n",
      "45.949528151516525\n",
      "55.50688190833305ion #51\n",
      "66.45828784436688\n",
      "59.896247476139386on #52\n",
      "63.872828412918196\n",
      "59.851271924255066on #53\n",
      "70.27691899586411\n",
      "55.535632119392346on #54\n",
      "60.1370783793616\n",
      "64.16146184971862ion #55\n",
      "56.931585127504974\n",
      "68.54775199250805ion #56\n",
      "61.58299976503422\n",
      "56.862182228631994on #57\n",
      "60.90166912923984\n",
      "53.663142704577915on #58\n",
      "54.556347489816\n",
      "66.10644694693403ion #59\n",
      "58.133541314374426\n",
      "52.53220137601381ion #60\n",
      "65.37971624951327\n",
      "63.51217311660185ion #61\n",
      "53.55405388085378\n",
      "66.68461797052535ion #62\n",
      "56.014016420390384\n",
      "54.1670139130016tion #63\n",
      "57.14796998661082\n",
      "64.28257612711393ion #64\n",
      "60.50196766962254\n",
      "54.247037837269325on #65\n",
      "60.07550057919582\n",
      "62.568992924629924on #66\n",
      "61.104871814210654\n",
      "59.3251856415663tion #67\n",
      "50.74877963128912\n",
      "64.56032042144162ion #68\n",
      "56.24795382611971\n",
      "59.58602712671127ion #69\n",
      "57.48059183419961\n",
      "56.64638549803288ion #70\n",
      "57.57060394779404\n",
      "59.46362463986836ion #71\n",
      "66.03115828849393\n",
      "56.393042115302926on #72\n",
      "63.755507246970474\n",
      "46.13425920578348ion #73\n",
      "52.50596776931539\n",
      "66.4942779628307tion #74\n",
      "64.52424045980479\n",
      "69.01573441894212ion #75\n",
      "53.20044011038395\n",
      "55.51887944848258ion #76\n",
      "61.17229931802728\n",
      "56.88768644083394ion #77\n",
      "61.825761427274344\n",
      "60.26792459210467ion #78\n",
      "73.20303048298189\n",
      "52.496193750215625on #79\n",
      "51.48476142381699\n",
      "52.45163432579601ion #80\n",
      "52.694401877704564\n",
      "58.17305137010771ion #81\n",
      "55.455474135573695\n",
      "63.744076587414305on #82\n",
      "51.78590007792057\n",
      "52.206461281282365on #83\n",
      "57.24988471129857\n",
      "65.89159018424637ion #84\n",
      "64.15967170383786\n",
      "50.28961245190358ion #85\n",
      "62.65975726028186\n",
      "64.58624908246657ion #86\n",
      "46.335475657698865\n",
      "55.69335935175276ion #87\n",
      "60.04909154629862\n",
      "66.67702564299371ion #88\n",
      "59.625546654990494\n",
      "52.69381225369943ion #89\n",
      "63.158452588062175\n",
      "54.83345988092716ion #90\n",
      "60.041322715052125\n",
      "62.961609904111626on #91\n",
      "53.9545370507166\n",
      "66.20727369441923ion #92\n",
      "52.06990005117992\n",
      "62.605227229367785on #93\n",
      "54.29427036614438\n",
      "56.381641976592185on #94\n",
      "53.94535387035593\n",
      "61.71073046551335ion #95\n",
      "56.680822283562556\n",
      "65.46120910638946ion #96\n",
      "47.38038094805054\n",
      "76.62542491253599ion #97\n",
      "56.23414222834355\n",
      "61.98177854159168ion #98\n",
      "61.59260479091643\n",
      "58.738318350658545on #99\n",
      "60.85990816254569\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAakUlEQVR4nO3df5DcdX3H8ec7xwqb0rIgN05yJE2qNBmUkugVcdJpTVobxbZESgWnrdo6pa0wlZZmTFqnwFiHtCmmdqbFiQMVlIFEoGcEnYyadJwyTZgLlx8ESE0FgSVKFC6KucbL5d0/9vO97G2+393v7u3P774eMzfZ+3y/u/fZL8v7Pvf+fj7vj7k7IiKSLXM63QEREWk+BXcRkQxScBcRySAFdxGRDFJwFxHJoLM63QGACy+80BctWtTpboiI9JQ9e/b8wN0H4451RXBftGgRo6Ojne6GiEhPMbPvJh1TWkZEJIMU3EVEMkjBXUQkgxTcRUQySMFdRCSDas6WMbNzgG8BZ4fzH3T3W8zs88CvAcfCqR92971mZsBngCuB46H9iVZ0XkSkF42MFdm4/RAvjU8wv5Bn7eolrFk+1NSfkWYq5Alglbu/ZmY54L/M7Gvh2Fp3f7Di/PcAF4evtwN3hn9FRPreJ0YOcN+u54nq8RbHJ1j/8AGApgb4mmkZL3ktfJsLX9XqBF8F3BuetwsomNm82XdVRKS3jYwVZwT2yMTkFBu3H2rqz0qVczezATPbC7wMfN3dd4dDnzKz/Wa2yczODm1DwAtlT38xtFW+5vVmNmpmo0ePHm38HYiI9IiN2w8ljoxfGp9o6s9KFdzdfcrdlwEXAZeb2VuA9cBS4JeBC4CP1/OD3X2zuw+7+/DgYOzqWRGRTKkWwAtzc039WXXNlnH3cWAn8G53PxJSLyeAfwcuD6cVgQVlT7sotImI9LX5hXzisdf+7yQjY80LlTWDu5kNmlkhPM4D7wKeifLoYXbMGuDJ8JRtwAet5ArgmLsfaVqPRUR61MqlyVmKyVPe1Lx7mtky84B7zGyA0i+Dre7+iJntMLNBwIC9wJ+F879KaRrkYUpTIf+oab0VEelhO5+pfn+xmXn3msHd3fcDy2PaVyWc78ANs++aiEi21Are1dI29dIKVRGRNqkWvPO5AdauXtK0n6XgLiLSJmtXLyGfGzijvZDPcfvVlzZ1EVNXbNYhItJLGi0fEJ3T6tIDoOAuIlKXkbEi6x8+wMTkFFB/+YA1y4daEswrKS0jIlKHjdsPTQf2SCvKB8yWRu4iInVImvEStbej4mMaGrmLiNQhacbL/EJ+OmVTHJ/AOZ2yaebK07QU3EVE6hA34yWaxthNKRsFdxGROqxZPsTtV1/KUCGPAUOF/PQ0xlopm3ZSzl1EpE5JM17mF/IUYwJ5M1eepqWRu4hImZGxIis27GDxukdZsWFHXfnyaimbdtPIXUQkaMYcdmjPIqVaFNxFRILbvnIw8YZo2gDdrkVKtSi4i0jfKp+TXpib49Xjk7HndeKG6GwpuItIX6pMwSQFdujMDdHZ0g1VEelLcXPSk3TihuhsKbiLSF9Km2op5HNdkUOvl4K7iPSlNKmWfG6AW3/nzW3oTfMpuItIpiXNW4+bk54bMAr53BkrT3uRbqiKSE9opNpimnnr3TAnvRUU3EWk6zW6uKhaIa9oPnpWgnklpWVEpOs1Wm2xmwp5tZtG7iLS9eoJ0uXpmzlmTLmfcU4vzluvl0buItL1qm2QUa5ys4y4wN6pQl7tpuAuIl0vbbXFpIVJA2aZmAFTD6VlRKTrpZ3ZkpS+OeXOsxve2/J+dhMFdxHpCWlmtnTTZhmdpuAuIl2n2pz2asfWrl4yY8ok9E+OvZKCu4h0lWpz2oGq892zvjCpHuYxd5PbbXh42EdHRzvdDRFpsTSrTFds2BGbWhkw4+fyZ8WW5h0q5Hls3aqW9btbmdkedx+OO6aRu4i03MhYkdu+cnBGYE5aZZp0U3TKPVObabSapkKKSEtFaZa4wBy3yrSRm5/9eMO0FgV3EWmpWptiVI664+a0V9OvN0xrUVpGRFpmZKwYmz8vFzfqPic3p+ovhAEzTrn39Q3TWhTcRaQlonRMNUYp975iww5WLh3kkX1HGJ9I3ss00o+LkupVMy1jZueY2eNmts/MDprZbaF9sZntNrPDZrbFzF4X2s8O3x8Oxxe1+D2ISBdKs0dpNFevOD7BF3c9nyqwg3LsaaTJuZ8AVrn7ZcAy4N1mdgXwD8Amd38T8CrwkXD+R4BXQ/umcJ6I9JlqM1gK+VzDr6scezo1g7uXvBa+zYUvB1YBD4b2e4A14fFV4XvC8V83M2tWh0WkNySNrocKeY6lHKFH+rHw12ylyrmb2QCwB3gT8K/A/wLj7n4ynPIiEF3tIeAFAHc/aWbHgNcDP6h4zeuB6wEWLlw4u3chIh2TtDCpWimAjdsP1bzRWv4cBfT6pQru7j4FLDOzAvAfwNLZ/mB33wxshtIK1dm+noi0X1KpgNHvvsLOZ44yMTnFQNgwY8Bsel77yqWDPLSnWDMnf/7cHLf89psV2BtQ12wZdx83s53AO4CCmZ0VRu8XAcVwWhFYALxoZmcB5wE/bGKfRaRLJG1/d9+u56dvlkYbZkT/FscneGhPkd992xA7nzk6PeJfuXRwxvea4jg7NYO7mQ0CkyGw54F3UbpJuhO4BngA+BDw5fCUbeH7/w7Hd3g3FLARkaZLumla63/4ickpdj5ztC/rwbRLmpH7POCekHefA2x190fM7CngATP7e2AMuCucfxfwBTM7DLwCXNeCfotIi6Qp7hVJqp+ehurBtFbN4O7u+4HlMe3fAS6Paf8/4Pea0jsRaatq5XbjAnzcTVOj9sgdNFe91VRbRkSmJeXQK4t7jYwVWbFhB3+5ZS/n5OZQyOempyr+/hULqTX3WXPVW0/lB0RkWlKqpLz9EyMHZtwwffX4JPncAJuuXTY9uv/irucTf8aQbpa2hUbuIjItKVUStY+MFWcE9kjl6H6oygKmx9atUmBvAwV3EZkWV263PIWycfuhxHx6+ei+1utI6yktIyLTKvcgLczN4Q5/uWVvzVWl5aN+7WXaedpDVURiVc6cgeSZMAYzcu7SHtX2UFVaRkRixc2cSQrsv3/FQgX2LqO0jIjESrPISLVfupeCu0ifqrUSNc3q07mvO0uBvUspLSPSh6J8enF8Auf0StSRseL0OWk2qlYJge6lkbtIRlUbmVdbiRqdU35u0gheJQS6l0buIhlUa2SeFKwr29csH+Kxdav452uXad56j1FwF8mgWjViBhJ2vkxqX7N8iNuvvpShQl7b3fUIpWVEMqhWjZiphPUtSe1QCvAK5r1DI3eRDKpVI6Za7RfJBo3cRTKg8uZp3B6l5TnylUsHYys3rlw62LY+S2up/IBIj4srE5DPDczYo/S8fI6fnpzi+OSpqq8VVW2U3qDyAyIZlnTzNNqjdNO1y/jJiZM1Azto3nqWKLiL9LikgFwcn5hO10yeSvcXuuatZ4dy7iI9Kgrc1cJ2ZbqmGs1bzxYFd5EeFJdnjzMxOcWAWdUpjqCt77JIwV2kB8Xl2ZNMuZObY7GpmdyAsfGayxTUM0g5d5EeVKtaY7mhQp6Nv3cZhXxuRvv5c3MK7BmmkbtIjxkZKybuiFQpyqNrdWn/0chdpIeMjBW5eeu+VIEdUP2XPqbgLtIjopuotW6ORoYKeQX2Pqa0jEgPiEbsaQO7pjWKgrtIl0jaXCPtiL2Qz3FsYjJ2yzzpPwruIl2gct56tLkGpJ/2uPeW32xpH6W3KOcu0gVu+8rBxM010tR7UaleqaTgLtJhI2NFXj0+GXssStFUk5tjyq/LGRTcRTos2vouTpQ/r9y/tNy555yl/LqcQTl3kQ6rlnYpvzF605a9seeMJ4z6pb9p5C7SRCNjRVZs2MHidY+yYsMORsaKNZ+TlHYp36p6zfKhxLy6yvRKHAV3kSYZGSvyV1v2UhyfwCnNePmrLXtrBvhFr48Pzk6pZG/0/Lj0jOazS5Kawd3MFpjZTjN7yswOmtnHQvutZlY0s73h68qy56w3s8NmdsjMVrfyDYh0i/UP76dyr6NTob2aXd95NfFYNGMGSqP326++lKFCHqM0Q0blBSRJmpz7SeBmd3/CzH4W2GNmXw/HNrn7P5WfbGaXANcBbwbmA98ws19093T1SUV61ETCNnZJ7ZFai5PKc/IqACZp1Ry5u/sRd38iPP4x8DRQ7dN1FfCAu59w92eBw8DlzeisSK9aVCUHP2AW84zTlFOXRtSVczezRcByYHdoutHM9pvZ3WZ2fmgbAl4oe9qLxPwyMLPrzWzUzEaPHj1af89FOqCRG6aRaNVp5XM+8PYFic9RTl0alXoqpJmdCzwE3OTuPzKzO4FPUrrv80ngDuCP076eu28GNgMMDw+nrWAq0nZRzZfi+MSMOurlJQLWLB/iZ143wE9+Wnvbu43bD81Irfz9mksBuH/3CzNSNNr6TmbDPEWVOTPLAY8A29390zHHFwGPuPtbzGw9gLvfHo5tB2519/9Oev3h4WEfHR1t7B2ItFDavUoB5ubmcLxGfh1KUxyf3fDeJvRO+p2Z7XH34bhjaWbLGHAX8HR5YDezeWWnvQ94MjzeBlxnZmeb2WLgYuDxRjsv0km3bjuz5kuSNIEdlEOX9kiTllkB/CFwwMz2hra/AT5gZsso/ZX6HPCnAO5+0My2Ak9Rmmlzg2bKSC8aGSsyPtHc1Z/KoUu71Azu7v5fzFwsF/lqled8CvjULPol0nHVar7UwwzclUOX9lJtGZEEaUrtpjH/vDyPrVvVlNcSSUvlB0QSNCs33qxfEiL1UHAXSVCr1G5auoEqnaDgLpIgquVSyOem286fm2PFGy9I/RoGuoEqHaHgLlLDiZOnpzi+enySJ54/xoo3XhA7y6CSg26gSkcouIuQXFYgbnPqickpnvvhBJuuXTZdoTGpPoz2NpVO0WwZ6StRKYFob9IoZVK+CrW8rEDSzdCXxidmVGiMW8mqOe3SSQru0hdGxorcuu3gjEVJxfEJ1n5pH1PunKqowhHVgJlfyFOMCfCVN0mjIF/5i0MpGekUBXfJvE+MHOC+Xc8TV0VpsjKql3lpvJR6STsiV6116SYK7pJpI2PFxMBey/xCXiNy6VkK7pJpG7cfaiiwl4/ONSKXXqTZMpJpjawOHTDT3qTS8xTcJdPOK1uAVGlubg65gZlTGPO5Ae54/2UK7NLzFNwls0bGivzkpydjj/3BFQt56pPvYeM1l03PVR8q5DVil8xQzl0ya+P2Q0xOnZlxP39ubnprO+XTJas0cpfMSsq3jx9v7gYcIt1II3fpGXGrS6uNutMuQBLJIo3cpSdEy/uL4xM4p0sERDVg4sSV7FVJAOkXGrlLT0gq4BVthRc3otcCJOln5t7IEo/mGh4e9tHR0U53QzokTbpl8bpHExcj5XMDZ5QH0KwX6Qdmtsfdh+OOKS0jHZU23ZKUJx8wqzqiF+lXCu7SUUnplpu37psR4NeuXkJuzswFR7k5xlTCX57at1T6nYK7dES0OUbcbBaAKfczR/CV+2EYM7bAK6cZMdLvFNyl7cpTMdVU3jCtXJA0OeWYoRkxIjEU3KXt4lIxSaL0SrUFSbdffalKCIhU0FRIabt68uFReqXagiSVEBA5k0bu0naFucmVGsuVp1e0IEmkPhq5S9slLa0wSiV6j01MnjHfXQuSROqj4C5td2wivnCXAydOnmLTtctig7bSLyLpKS0jDYumMy5e9ygrNuyoWuelXLVpilqAJNIcCu7SkEYKeUXi8ufltABJZPYU3KUhtQp5VbNm+RC3X30pA1a5KqlEC5BEZk/BXRqSNLpOO+pes3yID7x9QeyxlUsHG+6XiJQouEtDkkbX9Yy6dz5ztK52EUlPs2WkqqRyvGtXL2H9wwfOKLW7cukgKzbsSDVdcbajfxFJVjO4m9kC4F7gDZRmq21298+Y2QXAFmAR8Bzwfnd/1cwM+AxwJXAc+LC7P9Ga7ksrRTdNowAe3TSF+HnnK5cO8tCeYtXzy2kbPJHWSZOWOQnc7O6XAFcAN5jZJcA64JvufjHwzfA9wHuAi8PX9cCdTe+1tEWtm6Zrlg/x2LpVPLvhvaxdvYT7d79Q101WrToVaZ2aI3d3PwIcCY9/bGZPA0PAVcA7w2n3AP8JfDy03+ulLZ52mVnBzOaF15EekjZtEo3w09RWr0zz/O7bhtj5zFGtOhVpsrpy7ma2CFgO7AbeUBawv0cpbQOlwP9C2dNeDG0zgruZXU9pZM/ChQvr7be0Qdq0Sa0qj9H5cWmeh/YUVcVRpAVSz5Yxs3OBh4Cb3P1H5cfCKL2uzVjdfbO7D7v78OCgpr51o7Rpk2o3QMvPn83ceBGpT6rgbmY5SoH9Pnd/ODR/38zmhePzgJdDexEon8B8UWiTHhMtNqpVK73a/qbl52t2jEj7pJktY8BdwNPu/umyQ9uADwEbwr9fLmu/0cweAN4OHFO+vXelKdaVNC2y8heBZseItE+akfsK4A+BVWa2N3xdSSmov8vMvg38Rvge4KvAd4DDwOeAjza/29JN0o7wNTtGpH3Mk4prt9Hw8LCPjo52uhtSJmnxUre+rkg/MrM97j4cd0wrVOUMaRYvNUo12UXaQ7VlZIaRsSI3b92nWS0iPU7BXabVsxhJRLqbgrtMS7sYSUS6n4K7TEu7GElEup+Cu0xLuxhJRLqfgrtMS5qHfsf7L1NgF+kxmgop0+JqtGseukhvUnDPsEYWDGkeukg2KLhnVCsXIolI91POPaNUXlekvym4Z5TK64r0NwX3jEqa1qiFSCL9QcE9o1ReV6S/6YZqRmlao0h/U3DvsFbWN9e0RpH+peDeQZquKCKtopx7ByVNV7x56z4Wr3uUFRt2MDKmvcVFpH4auXdQ0rTEqJ66RvIi0iiN3DsozbRELTwSkUYouHdQ3HTFOEUtPBKROikt00GV0xXjN7cr1VMXEamHgnuHlU9XXLTu0dhzkvY0FRFJorRMFxlKyMEntYuIJFFw7yIqGSAizaK0TBdRyQARaRYF9y6jkgEi0gxKy4iIZJBG7h3QymJhIiKg4N52KhYmIu2gtEybaW9TEWkHBfc2096mItIOCu5tpr1NRaQdFNzbTAuVRKQddEO1zbRQSUTaoWZwN7O7gd8CXnb3t4S2W4E/AY6G0/7G3b8ajq0HPgJMAX/h7ttb0O+epoVKItJqadIynwfeHdO+yd2Xha8osF8CXAe8OTzn38ysdsFyERFpqprB3d2/BbyS8vWuAh5w9xPu/ixwGLh8Fv0TEZEGzOaG6o1mtt/M7jaz80PbEPBC2TkvhrYzmNn1ZjZqZqNHjx6NO0VERBrUaHC/E3gjsAw4AtxR7wu4+2Z3H3b34cHBwQa7ISIicRoK7u7+fXefcvdTwOc4nXopAgvKTr0otImISBs1FNzNbF7Zt+8DngyPtwHXmdnZZrYYuBh4fHZdFBGReqWZCnk/8E7gQjN7EbgFeKeZLQMceA74UwB3P2hmW4GngJPADe4+FfOyIiLSQuZdsPny8PCwj46OdrobIiI9xcz2uPtw3DGVHxARySAFdxGRDFJwFxHJIAV3EZEMUnAXEckgBXcRkQxScBcRySAFdxGRDFJwFxHJIAV3EZEMUnAXEckgBXcRkQxScBcRyaCaJX+71chYkY3bD/HS+ATzC3nWrl7CmuWxO/qJiPSdngzuI2NF1j98gInJUqn44vgE6x8+AKAALyJCj6ZlNm4/NB3YIxOTU2zcfqhDPRIR6S49GdxfGp+oq11EpN/0ZHCfX8jX1S4i0m96MrivXb2EfG5gRls+N8Da1Us61CMRke7SkzdUo5ummi0jIhKvJ4M7lAK8grmISLyeTMuIiEh1Cu4iIhmk4C4ikkEK7iIiGaTgLiKSQebune4DZnYU+G749kLgBx3sTrfQdThN16JE1+E0XYuSn3f3wbgDXRHcy5nZqLsPd7ofnabrcJquRYmuw2m6FrUpLSMikkEK7iIiGdSNwX1zpzvQJXQdTtO1KNF1OE3Xooauy7mLiMjsdePIXUREZknBXUQkg9oe3M3sbjN72cyeLGu7wMy+bmbfDv+eH9rNzP7FzA6b2X4ze2u7+9sqCdfhVjMrmtne8HVl2bH14TocMrPVnel185nZAjPbaWZPmdlBM/tYaO/Hz0TSteirz4WZnWNmj5vZvnAdbgvti81sd3i/W8zsdaH97PD94XB8UUffQLdw97Z+Ab8KvBV4sqztH4F14fE64B/C4yuBrwEGXAHsbnd/23wdbgX+OubcS4B9wNnAYuB/gYFOv4cmXYd5wFvD458F/ie83378TCRdi776XIT/tueGxzlgd/hvvRW4LrR/Fvjz8PijwGfD4+uALZ1+D93w1faRu7t/C3ilovkq4J7w+B5gTVn7vV6yCyiY2by2dLTFEq5DkquAB9z9hLs/CxwGLm9Z59rI3Y+4+xPh8Y+Bp4Eh+vMzkXQtkmTycxH+274Wvs2FLwdWAQ+G9srPRPRZeRD4dTOz9vS2e3VLzv0N7n4kPP4e8IbweAh4oey8F6n+Yc+CG0O64e4oFUGfXIfw5/RySiO1vv5MVFwL6LPPhZkNmNle4GXg65T+Khl395PhlPL3On0dwvFjwOvb2uEu1C3BfZqX/rbq1/mZdwJvBJYBR4A7OtqbNjKzc4GHgJvc/Uflx/rtMxFzLfruc+HuU+6+DLiI0l8jSzvbo97TLcH9+9Gf1uHfl0N7EVhQdt5FoS2T3P374UN9Cvgcp//EzvR1MLMcpWB2n7s/HJr78jMRdy369XMB4O7jwE7gHZRScNHWoOXvdfo6hOPnAT9sb0+7T7cE923Ah8LjDwFfLmv/YJghcQVwrOxP9cypyB2/D4hm0mwDrguzAhYDFwOPt7t/rRByo3cBT7v7p8sO9d1nIula9NvnwswGzawQHueBd1G6/7ATuCacVvmZiD4r1wA7wl97/a3dd3CB+yn9aTlJKW/2EUr5sW8C3wa+AVzgp++a/yulfNsBYLjTd6BbfB2+EN7nfkof2Hll5/9tuA6HgPd0uv9NvA6/Qinlsh/YG76u7NPPRNK16KvPBfBLwFh4v08Cfxfaf4HSL6/DwJeAs0P7OeH7w+H4L3T6PXTDl8oPiIhkULekZUREpIkU3EVEMkjBXUQkgxTcRUQySMFdRCSDFNxFRDJIwV1EJIP+H2G9+qTWfe/bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_sampler(dim=10, mean_a=-100., mean_b=100., cov_a=-1., cov_b=1.):\n",
    "    A = np.random.uniform(cov_a, cov_b, size=(dim, dim))\n",
    "    cov = np.dot(A.T, A)\n",
    "    print(np.linalg.norm(cov))\n",
    "    mean = np.random.uniform(mean_a, mean_b, size=dim)\n",
    "    return mean, cov, lambda size: tf_sampler(mean, cov, size)\n",
    "\n",
    "\n",
    "num_exps = 100\n",
    "dim = 10\n",
    "num_samples = 100\n",
    "cov_a = -2.\n",
    "cov_b = -cov_a\n",
    "w_s = np.zeros(num_exps)\n",
    "w_f = np.zeros(num_exps)\n",
    "for i in range(num_exps):\n",
    "    print('Working on iteration #{}'.format(i), end='\\r')\n",
    "    mean_1, cov_1, sampler_1 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    mean_2, cov_2, sampler_2 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    samples_1 = sampler_1(num_samples)\n",
    "    samples_2 = sampler_2(num_samples)\n",
    "    w_s[i] = np.sqrt(tfw.sinkhorn_loss(samples_1, samples_2, epsilon=0.01, num_iters=50, p=2))\n",
    "    w_f[i] = exact_w2(mean_1, mean_2, cov_1, cov_2) \n",
    "\n",
    "plt.scatter(w_s, w_f)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "psychological-banking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on iteration #99\n",
      "Number of failures = 0\n"
     ]
    }
   ],
   "source": [
    "# Triangle inequality\n",
    "\n",
    "num_exps = 100\n",
    "dim = 10\n",
    "num_samples = 200\n",
    "tri = np.zeros(num_exps)\n",
    "cov_a = -10.\n",
    "cov_b = -cov_a\n",
    "for i in range(num_exps):\n",
    "    print('Working on iteration #{}'.format(i), end='\\r')\n",
    "    mean_1, cov_1, sampler_1 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    mean_2, cov_2, sampler_2 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    mean_3, cov_3, sampler_3 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    samples_1 = sampler_1(num_samples)\n",
    "    samples_2 = sampler_2(num_samples)\n",
    "    samples_3 = sampler_3(num_samples)\n",
    "    w_12 = np.sqrt(tfw.sinkhorn_loss(samples_1, samples_2, epsilon=0.01, num_iters=50, p=2))\n",
    "    w_23 = np.sqrt(tfw.sinkhorn_loss(samples_2, samples_3, epsilon=0.01, num_iters=50, p=2))\n",
    "    w_13 = np.sqrt(tfw.sinkhorn_loss(samples_1, samples_3, epsilon=0.01, num_iters=50, p=2))\n",
    "    if w_12 + w_23 >= w_13:\n",
    "        tri[i] = 1.0\n",
    "print('\\nNumber of failures = {}'.format(num_exps - int(tri.sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "raising-basic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.699871458401564on #0\n",
      "16.76883834455234\n",
      "14.293692413219672on #1\n",
      "13.407910249475403\n",
      "14.011974809950193on #2\n",
      "14.99734409766792\n",
      "14.406216159891267on #3\n",
      "13.159388423086902\n",
      "15.023351516041505on #4\n",
      "14.094890190470561\n",
      "13.080523961228907on #5\n",
      "14.420514811581596\n",
      "14.983384885574157on #6\n",
      "14.372005725122301\n",
      "13.936690898700546on #7\n",
      "15.178562934783299\n",
      "18.19225591480716ion #8\n",
      "12.550024926068081\n",
      "13.515316445506906on #9\n",
      "13.826960032823388\n",
      "14.635924528570827on #10\n",
      "13.884075918446788\n",
      "17.74089147720352ion #11\n",
      "14.8381644165007\n",
      "16.12390490178295ion #12\n",
      "14.146568199501809\n",
      "15.340511215477584on #13\n",
      "15.810464773326261\n",
      "14.07431832717446ion #14\n",
      "15.816751782541512\n",
      "14.820147713457466on #15\n",
      "14.850133701611066\n",
      "14.455503220124957on #16\n",
      "15.220832706465927\n",
      "15.713271435812011on #17\n",
      "15.056726621013256\n",
      "14.733170388259419on #18\n",
      "15.327659998394566\n",
      "13.52367813252385ion #19\n",
      "15.746484616339448\n",
      "18.917464590534994on #20\n",
      "14.322836887893967\n",
      "14.267999406714448on #21\n",
      "13.689673868239082\n",
      "12.756050802488392on #22\n",
      "13.11637162786462\n",
      "15.758479332243189on #23\n",
      "17.314944421942887\n",
      "14.80604776642804ion #24\n",
      "15.104667277353993\n",
      "16.263523324177434on #25\n",
      "12.72507363266779\n",
      "16.83342905263111ion #26\n",
      "13.259234398085814\n",
      "13.220290834130129on #27\n",
      "13.207484056364958\n",
      "16.566777646435792on #28\n",
      "16.380812822289446\n",
      "11.411944758354535on #29\n",
      "16.58990910549933\n",
      "13.387434998511129on #30\n",
      "13.178350133028959\n",
      "13.390048846712059on #31\n",
      "12.703720946382875\n",
      "14.936306921072063on #32\n",
      "14.96443932879444\n",
      "14.277662430135466on #33\n",
      "13.893159958261062\n",
      "15.870736935164855on #34\n",
      "14.751902405858726\n",
      "13.642207840617695on #35\n",
      "14.807368569758822\n",
      "14.407743053642383on #36\n",
      "15.044443695578583\n",
      "15.499139022461204on #37\n",
      "17.26178524963586\n",
      "12.88388961727198ion #38\n",
      "14.024045733567192\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-deb0180fcdfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0msamples_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampler_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0msamples_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampler_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mw_12\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msinkhorn_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mw_21\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msinkhorn_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#print(w_12, w_21)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\Wasserstein\\modules\\wasserstein.py\u001b[0m in \u001b[0;36msinkhorn_loss\u001b[1;34m(x, y, x_weights, y_weights, epsilon, num_iters, p)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_weights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m  \u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_weights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mlse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\Wasserstein\\modules\\wasserstein.py\u001b[0m in \u001b[0;36mM\u001b[1;34m(u, v)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;34m\"Modified cost for logarithmic updates\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;34m\"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_logsumexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mneg\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m   6233\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6234\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6235\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   6236\u001b[0m         _ctx, \"Neg\", name, x)\n\u001b[0;32m   6237\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Symmetry\n",
    "\n",
    "num_exps = 100\n",
    "dim = 10\n",
    "num_samples = 200\n",
    "sym = np.zeros(num_exps)\n",
    "cov_a = -1.\n",
    "cov_b = -cov_a\n",
    "for i in range(num_exps):\n",
    "    print('Working on iteration #{}'.format(i), end='\\r')\n",
    "    mean_1, cov_1, sampler_1 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    mean_2, cov_2, sampler_2 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    samples_1 = sampler_1(num_samples)\n",
    "    samples_2 = sampler_2(num_samples)\n",
    "    w_12 = np.sqrt(tfw.sinkhorn_loss(samples_1, samples_2, epsilon=0.01, num_iters=500, p=2))\n",
    "    w_21 = np.sqrt(tfw.sinkhorn_loss(samples_2, samples_1, epsilon=0.01, num_iters=500, p=2))\n",
    "    #print(w_12, w_21)\n",
    "    if abs(w_12 - w_21)/w_12 < 1e-2:\n",
    "        sym[i] = 1.0\n",
    "print('\\nNumber of failures = {}'.format(num_exps - int(sym.sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "different-halloween",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on iteration #99\n",
      "Number of failures = 0\n"
     ]
    }
   ],
   "source": [
    "# Identity\n",
    "\n",
    "num_exps = 100\n",
    "dim = 10\n",
    "num_samples = 200\n",
    "id_ = np.zeros(num_exps)\n",
    "cov_a = -10.\n",
    "cov_b = -cov_a\n",
    "for i in range(num_exps):\n",
    "    print('Working on iteration #{}'.format(i), end='\\r')\n",
    "    mean_1, cov_1, sampler_1 = generate_sampler(dim=dim, cov_a=cov_a, cov_b=cov_b)\n",
    "    samples_1 = sampler_1(num_samples)\n",
    "    w = np.sqrt(tfw.sinkhorn_loss(samples_1, samples_1, epsilon=0.01, num_iters=50, p=2))\n",
    "    if w == 0.:\n",
    "        id_[i] = 1.0\n",
    "print('\\nNumber of failures = {}'.format(num_exps - int(id_.sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-conditions",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
