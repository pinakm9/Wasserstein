{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spiritual-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add modules to Python's search path\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import  torch\n",
    "#from geomloss import SamplesLoss\n",
    "import tensorflow as tf\n",
    "from modules import wasserstein as tfw\n",
    "import tensorflow_probability as tfp\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "miniature-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nuse_cuda = torch.cuda.is_available()\\n# N.B.: We use float64 numbers to get nice limits when blur -> +infinity\\ndtype    = torch.cuda.DoubleTensor if use_cuda else torch.DoubleTensor\\n\\n# make a convenient wrapper for producing samples in form of a tensor\\ndef torch_sampler(mean, cov, size):\\n    samples = np.random.multivariate_normal(mean, cov, size)\\n    return torch.from_numpy(samples)\\n\\n# set up parameters for our two test distributions\\ndimension = 3\\nmean_1 = np.zeros(dimension)\\nmean_2 = mean_1 + 0.1 * np.ones(dimension)\\ncov_1 = np.identity(dimension)\\ncov_2 = cov_1\\n\\n# finally create the samplers our test distributions\\nsampler_1 = lambda size: torch_sampler(mean_1, cov_1, size)\\nsampler_2 = lambda size: torch_sampler(mean_2, cov_2, size)\\n\\n# test our samplers\\nprint(\"samples from distribution #1:\\n{}\".format(sampler_1(3)))\\nprint(\"samples from distribution #2:\\n{}\".format(sampler_2(3)))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# N.B.: We use float64 numbers to get nice limits when blur -> +infinity\n",
    "dtype    = torch.cuda.DoubleTensor if use_cuda else torch.DoubleTensor\n",
    "\n",
    "# make a convenient wrapper for producing samples in form of a tensor\n",
    "def torch_sampler(mean, cov, size):\n",
    "    samples = np.random.multivariate_normal(mean, cov, size)\n",
    "    return torch.from_numpy(samples)\n",
    "\n",
    "# set up parameters for our two test distributions\n",
    "dimension = 3\n",
    "mean_1 = np.zeros(dimension)\n",
    "mean_2 = mean_1 + 0.1 * np.ones(dimension)\n",
    "cov_1 = np.identity(dimension)\n",
    "cov_2 = cov_1\n",
    "\n",
    "# finally create the samplers our test distributions\n",
    "sampler_1 = lambda size: torch_sampler(mean_1, cov_1, size)\n",
    "sampler_2 = lambda size: torch_sampler(mean_2, cov_2, size)\n",
    "\n",
    "# test our samplers\n",
    "print(\"samples from distribution #1:\\n{}\".format(sampler_1(3)))\n",
    "print(\"samples from distribution #2:\\n{}\".format(sampler_2(3)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wrong-thermal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnum_samples_1 = 500\\nnum_samples_2 = 500\\nsamples_1 = sampler_1(num_samples_1)\\nsamples_2 = sampler_2(num_samples_2)\\nloss = SamplesLoss(\"sinkhorn\", p=2, blur=0.01, scaling=.99, backend=\"online\")\\nprint(np.sqrt(loss(samples_1, samples_2).item()))\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "num_samples_1 = 500\n",
    "num_samples_2 = 500\n",
    "samples_1 = sampler_1(num_samples_1)\n",
    "samples_2 = sampler_2(num_samples_2)\n",
    "loss = SamplesLoss(\"sinkhorn\", p=2, blur=0.01, scaling=.99, backend=\"online\")\n",
    "print(np.sqrt(loss(samples_1, samples_2).item()))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "square-script",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples from distribution #1:\n",
      "[[ 0.1426911   0.82277864 -1.0942844 ]\n",
      " [-2.349682   -0.651521    0.3876022 ]\n",
      " [ 1.6059172  -0.55878234 -0.3434317 ]]\n",
      "samples from distribution #2:\n",
      "[[ 99.86232  99.5773   99.85972]\n",
      " [101.8448   99.35104  99.58414]\n",
      " [ 99.00876 100.09715 101.11506]]\n"
     ]
    }
   ],
   "source": [
    "# make a convenient wrapper for producing samples in form of a tensor\n",
    "def tf_sampler(mean, cov, size):\n",
    "    samples = np.random.multivariate_normal(mean, cov, size)\n",
    "    return tf.convert_to_tensor(samples, dtype=tf.float32)\n",
    "\n",
    "# set up parameters for our two test distributions\n",
    "dimension = 3\n",
    "mean_1 = np.zeros(dimension)\n",
    "mean_2 = mean_1 + 100.0 * np.ones(dimension)\n",
    "cov_1 = np.identity(dimension)\n",
    "cov_2 = cov_1\n",
    "\n",
    "# finally create the samplers our test distributions\n",
    "sampler_1 = lambda size: tf_sampler(mean_1, cov_1, size)\n",
    "sampler_2 = lambda size: tf_sampler(mean_2, cov_2, size)\n",
    "\n",
    "# test our samplers\n",
    "print(\"samples from distribution #1:\\n{}\".format(sampler_1(3)))\n",
    "print(\"samples from distribution #2:\\n{}\".format(sampler_2(3)))\n",
    "\n",
    "# Wasserstein_2 formula\n",
    "def w2_formula(ensemble_1, ensemble_2, tf=True):\n",
    "    if tf:\n",
    "        ensemble_1 = ensemble_1.numpy()\n",
    "        ensemble_2 = ensemble_2.numpy()\n",
    "    m1 = np.mean(ensemble_1, axis=0)\n",
    "    m2 = np.mean(ensemble_2, axis=0)\n",
    "    C1 = np.cov(ensemble_1.T)\n",
    "    C2 = np.cov(ensemble_2.T)\n",
    "    r_C2 = sp.linalg.sqrtm(C2)\n",
    "    term_1 = np.linalg.norm(m1 - m2, ord=2)\n",
    "    term_2 = np.trace( C1 + C2 - 2.0 * sp.linalg.sqrtm(np.linalg.multi_dot([r_C2, C1, r_C2])) )\n",
    "    return np.sqrt(term_1**2 + term_2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "golden-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wasserstein_2, computed with Sinkhorn algorithm: 173.28921508789062\n",
      "Wasserstein_2, computed with formula: 173.36660779837285\n"
     ]
    }
   ],
   "source": [
    "num_samples_1 = 200\n",
    "num_samples_2 = 200\n",
    "samples_1 = sampler_1(num_samples_1)\n",
    "samples_2 = sampler_2(num_samples_2)\n",
    "loss = tfw.sinkhorn_loss(samples_1, samples_2, epsilon=0.01, num_iter=2000, p=2)\n",
    "print(\"Wasserstein_2, computed with Sinkhorn algorithm: {}\".format(np.sqrt(loss)))\n",
    "print(\"Wasserstein_2, computed with formula: {}\".format(w2_formula(samples_1, samples_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-matter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
